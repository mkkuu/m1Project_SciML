{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "# 14. Construction de l'état réduit \n",
    "\n",
    "---\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "## 1. Objectif et positionnement\n",
    "\n",
    "\n",
    "> #### Quel est l'état à retenir ?\n",
    "\n",
    "Rappelons en condensé ce qui a été énoncé dans le notebook 10.\n",
    "\n",
    "En l'état, nous démarrons le pré-traitement avec un champs spatial de SST qui évolue dans le temps avec des milliers de points spatiaux corrélés entre eux. \n",
    "\n",
    "La réduction de dimensionnalité est nécessaire pour clarifier ce qu'on veut faire apprendre à notre futur modèle. Je cite la partie 1. du notebook 10 : \"Sans cela, on s'expose à un apprentissage instable, une sur-paramétrisation massive et une interprétation impossible. Le modèle ne doit apprendre ni le bruit, ni la grille, mais la dynamique.\".\n",
    "\n",
    "La nature géophysique des champs avec lesquels nous travaillons nous avait amené à penser que l'EOF serait la méthode adaptée pour réduire notre série d'anomalies de SST désaisonnalisée. On transforme ainsi notre matrice actuelle de la manière suivante :\n",
    "\n",
    "$$ X(x, y, t) \\approx \\overset{K}{\\underset{k=1}{\\sum}}a_k(t)\\phi_k(x,y) $$\n",
    "\n",
    "Nous permettant d'obtenir le vecteur d'état composait des amplitudes de l'EOF de l'équation précédente, soit :\n",
    "\n",
    "$$\n",
    "\\dot{a}_k(t) = f(\\begin{pmatrix} a_1(t) \\\\ a_2(t) \\\\ \\vdots \\\\ a_k(t) \\end{pmatrix})\n",
    "$$\n",
    "\n",
    "Finalement, on fournit l'état dynamique réduit suivant au modèle SciML :\n",
    "\n",
    "$$\n",
    "\\dot{a}_k(t) = \\begin{pmatrix} \\dot{a}_k(t) \\\\ \\dot{a}_2(t) \\\\ \\vdots \\\\ \\dot{a}_1(t) \\end{pmatrix} = f_\\theta(a_1(t), a_2(t),..., a_k(t))\n",
    "$$\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "---\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "## 2. Construction de l’état réduit par EOF\n",
    "\n",
    "Commençons dès maintenant par réduire notre matrice étant donné que nous avions fait les vérifications dans l'analyse multivariée (voir Notebook 10).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Load deseasonalized SST data\n",
    "ds = xr.open_dataset(\"data/processed/sstDeseasonalizedCOPERNICUS20102019.nc\")\n",
    "\n",
    "# Extract SST data and reshape for PCA\n",
    "sst = ds[\"analysed_sst\"]\n",
    "sstStacked = sst.stack(space=(\"latitude\", \"longitude\"))\n",
    "sstStacked = sstStacked.dropna(\"space\")\n",
    "\n",
    "X = sstStacked.values  # shape (Nt, Nspace)\n",
    "\n",
    "K = 150  # Number of principal components to retain plus some margin if we want to test more later\n",
    "\n",
    "pca = PCA(n_components=K, svd_solver=\"full\")\n",
    "PCs = pca.fit_transform(X)        # a_k(t)\n",
    "EOFs = pca.components_            # phi_k(x)\n",
    "explainedVar = pca.explained_variance_ratio_\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12 (flake)",
   "language": "python",
   "name": "flake-py312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
