{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "# 15. Pré-traitement numérique pour SciML\n",
    "\n",
    "---\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "Ce notebook vise à préparer l’état réduit issu de l’analyse EOF afin qu’il soit compatible avec l’apprentissage de modèles dynamiques SciML, cela en garantissant la stabilité numérique, l’absence de fuite d’information et la cohérence temporelle. On peut le réduire à une question centrale.\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "> #### Est-ce mon état réduit est numériquement sain pour apprendre une dynamique ?\n",
    "\n",
    "L’état réduit est constitué des $K$ premiers coefficients EOF (~150 modes dans le NetCDF), stockés sous la forme d’une série temporelle multivariée.\n",
    "\n",
    "Ce que l'on connaît des modèles dynamique SciML, c'est leur tendance à être sensible aux échelles. Nous l'apprenons de cette source Application of Reduced-Order Models for Temporal Multiscale Representations in the Prediction of Dynamical Systems (https://arxiv.org/html/2510.18925v1) après une recherche avec le mot-clé \"Model Reduction\".\n",
    "\n",
    "Globalement, ce que l'on en retire, c'est que ce type de modèle est conçu pour apprendre une loi d'évolution temporelle. Si l'état réduit \"contient\" des composantes associées à diverses échelles temporelles, le modèle appliqué doit réussir à différencier ces échelles au risque de sur-lisser ou ne modèliser qu'une seule échelle.\n",
    "\n",
    "Dans un système réel (comme la SST), il existe des interactions entre échelles lentes et rapides (ou un spectre de K échelles). Les approches dites \"naïves\" peinent à capturer ces comportements qui opèrent simultanément sur le même jeu de données. \n",
    "\n",
    "Chaque mode (ou degré de liberté) peut donc évoluer à son propre rythme, et dans un système tel à plusieurs échelles, il nous faut au plus simplifier ce travail de différenciation pour que la formulation proposée par la modélisation dynamique SciML reproduise au plus fidèlement les signatures lentes/rapides et leurs couplages(ou le fait que l'évolution d’une composante du système dépend de l’état d’une ou plusieurs autres composantes). Exemple : un gradient thermique large échelle (EOF 1) peut conditionner l’intensité des fronts côtiers (EOF 3).\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "---\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "## 2. Normalisation et mise à l'échelle\n",
    "\n",
    "> #### Pourquoi faire cela ?\n",
    "\n",
    "La normalisation et la mise à l'échelle sont une réponse simple et efficace au problème de différencition d'échelles exprimée ci-dessus. On veut éviter qu'un mode ne domine trop numériquement. Mathématiquement cela se traduit par une normalisation par l'écart-type (ou scaling), comme suit :\n",
    "\n",
    "$$\n",
    "\\tilde{a}_k(t) = \\frac{a_k(t)}{\\sigma_k}\n",
    "$$\n",
    "où :\n",
    "- $\\tilde{a}_k(t)$ : état réduit $k$ normalisé de sortie\n",
    "- $a_k(t)$ : état réduit $k$ d'entrée \n",
    "- $\\sigma_k$ : écart-type des PCs\n",
    "\n",
    "En effet, diviser par l'écart-type ajuste notre état réduit de manière à affaiblir les PCs qui dominent et renforcer ceux qui sont dominés.\n",
    "\n",
    "&nbsp;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.23361372e-06  5.43166081e-08  1.03606318e-07 -5.01841100e-07\n",
      "  1.06021844e-07  2.24186579e-07 -2.36851747e-07  1.96359110e-07\n",
      "  1.07066391e-08  7.57298864e-08 -1.63406824e-07 -2.90025888e-08\n",
      "  6.17590317e-08  1.07066391e-08  2.18572126e-07  1.99182665e-07\n",
      " -1.27663611e-07  8.63508447e-08 -9.18714562e-08 -6.73612490e-08\n",
      " -5.44798198e-08  8.75055619e-08  4.72495749e-08  3.06020560e-08\n",
      " -4.69394728e-08  3.78649423e-09  2.03483275e-08  8.17360544e-08\n",
      " -1.51786193e-08 -1.24693173e-07  5.24478452e-08  6.78304772e-08\n",
      "  2.88556983e-08  9.12675731e-08 -1.70392251e-08  3.54494212e-08\n",
      " -2.70277365e-08 -3.44048701e-08  5.81031045e-09 -1.14492494e-07\n",
      " -5.69606273e-09 -2.30780302e-08 -1.44931338e-08 -1.56437707e-08\n",
      "  6.02738126e-08  4.19452162e-09 -4.52747209e-08 -5.74502579e-09\n",
      "  2.79417165e-08 -1.03149329e-08  3.84198628e-08  4.18636148e-09\n",
      "  3.71794577e-08  1.53907944e-08 -4.21084287e-08 -3.00716216e-08\n",
      " -4.14882280e-08  9.77633690e-08 -1.80837745e-08 -6.29846397e-08\n",
      "  2.38288012e-09 -2.69624518e-08 -1.69086558e-08 -5.36148015e-08\n",
      " -2.34370940e-08  2.04503348e-08  2.35023800e-09 -1.94221048e-08\n",
      " -3.02552339e-09 -8.97660346e-09  2.55669974e-08  5.74829038e-08\n",
      " -4.52747209e-08 -3.87707644e-08 -3.83545778e-10 -3.06265378e-08\n",
      " -6.52027810e-09 -1.19837651e-08 -3.18587823e-08 -1.14696510e-08\n",
      "  2.56812456e-08 -3.61512287e-09 -8.38496328e-10 -9.09085074e-09\n",
      " -6.02901338e-08 -3.58737715e-08 -3.44375124e-08  9.79102595e-08\n",
      " -1.96261194e-08 -2.30372272e-08 -5.18358014e-08 -5.53285195e-09\n",
      "  2.32738842e-08  1.93649807e-08  3.24626619e-08 -3.74242752e-08\n",
      "  7.62195196e-09  1.73003620e-08 -2.82599792e-08 -2.10623750e-08\n",
      " -1.41259093e-08  2.17988649e-08 -3.52780489e-08  2.54099071e-08\n",
      " -5.36964073e-09 -1.17715908e-08  4.09088301e-08  1.08290479e-08\n",
      " -1.62068492e-08 -2.23272600e-08 -5.04321873e-09 -2.70721081e-08\n",
      "  1.66475189e-09 -1.53744733e-08 -1.94261851e-08 -4.83104445e-09\n",
      "  8.73178641e-10 -3.13467052e-09  3.72121001e-09 -6.92626534e-09\n",
      " -1.12176934e-08  5.91639759e-09  1.02822906e-08 -6.08980910e-09\n",
      " -7.34449376e-11 -3.92767205e-08  3.39478801e-09 -3.19975086e-08\n",
      " -1.03394147e-08  2.52977000e-10 -5.45940670e-09 -1.32833327e-08\n",
      " -2.36655895e-09  4.17820090e-08  3.20668754e-08 -1.77124697e-08\n",
      " -1.61170828e-08 -1.89324716e-08 -9.79265780e-10 -1.13268408e-08\n",
      "  1.45910599e-08 -9.80081882e-09 -1.22734649e-08  2.19110721e-08\n",
      "  1.36852396e-08  4.50951916e-08 -2.35839845e-08  4.76249582e-08\n",
      " -4.34630785e-08  4.55276989e-08]\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "dsReducedState = xr.open_dataset(\"data/processed/sstReducedStateCOPERNICUS20102019.nc\")\n",
    "\n",
    "PCs = dsReducedState[\"PCs\"].values\n",
    "\n",
    "# We recheck if PCs are welled centered\n",
    "print(PCs.mean(axis=0))  # Should be close to zero\n",
    "\n",
    "Nt = PCs.shape[0]\n",
    "trainRatio = 0.8\n",
    "trainEnd = int(trainRatio * Nt)\n",
    "\n",
    "# Temporal splitting\n",
    "PCsTrain = PCs[:trainEnd]\n",
    "PCsVal   = PCs[trainEnd:]\n",
    "\n",
    "# Normalization only on training data so we avoid data leakage (lookahead bias)\n",
    "meanTrain = PCsTrain.mean(axis=0)\n",
    "stdTrain  = PCsTrain.std(axis=0)\n",
    "PCsTrainScaled = (PCsTrain - meanTrain) / stdTrain\n",
    "PCsValScaled   = (PCsVal   - meanTrain) / stdTrain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "On revérifie que le centrage est correct pour garantir l'absence de biais constant dans la dynamique que l'on souhaite apprendre. On constate la moyenne de chaque PC est proche de 0 (de l'ordre du dix-millième au cent-milliardième selon le PC)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12 (flake)",
   "language": "python",
   "name": "flake-py312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
