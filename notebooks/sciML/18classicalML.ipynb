{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "612bde4e",
   "metadata": {},
   "source": [
    "# Classic Machine Learning\n",
    "## Introduction\n",
    "### Pourquoi faire du Machine Learning Classique ?\n",
    "Le but du machine learning classique ici est de vérifier si l'utilisation du SciML dans notre projet présente un interêt ou bien si on peut se contenter d'un modèle plus simple.\n",
    "\n",
    "### Chargement et vérification des données\n",
    "On commence par charger notre état réduit prétraité puis on vérifie ensuite que nos données sont cohérentes pour s'assurer de la précision de nos modélisations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1ef9de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2922, 150) (730, 150)\n",
      "(2922,) (730,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "data = np.load(\"../../data/processed/sstReducedStateCOPERNICUS20102019Prepared.npz\")\n",
    "# data contient le résultat final du prétraitement\n",
    "\n",
    "PCsTrain = data[\"PCsTrain\"] # Coefficients temporels des modes EOF\n",
    "PCsVal = data[\"PCsVal\"] # PCsTrain sur période future\n",
    "tTrain = data[\"tTrain\"] # Vecteur temps de PCsTrain\n",
    "tVal = data[\"tVal\"] # Vecteur temps de PCsVal\n",
    "std = data[\"std\"] # Ecart-type de chaque mode PCA\n",
    "\n",
    "# Vérifications (à supprimer) ############\n",
    "\n",
    "print(PCsTrain.shape, PCsVal.shape)\n",
    "print(tTrain.shape, tVal.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c13a0e",
   "metadata": {},
   "source": [
    "### A quoi sert exactement ce code ?\n",
    "Notre code nous permet de connaître :\n",
    "- l'état du système à un instant donné avec un mode spatial grâce à PCsTrain, il s'agit de notre état réduit $u(t)$\n",
    "- l'état du système sur une période temporelle future PCsVal, il ne sera jamais vue par nos modèles pendant l'apprentissage \n",
    "- le vecteur temporel tTrain afin de vérifier la cohérence temporelle afin de garantir un split temporel strict\n",
    "- le vecteur temporel tVal pour délimiter correctement le passé et le futur\n",
    "- l'écart-type de chaque mode PCA std qui permet de connaître l'ordre de grandeur physique de chaque mode et interpréter les erreurs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99e4cb5",
   "metadata": {},
   "source": [
    "## One-step forecast\n",
    "### Pourquoi fait-on un one-step forecast ?\n",
    "On veut créer un modèle qui puisse apprendre la dynamique de notre système plutôt que de simplement réaliser une prédiction. Pour ce faire on demande au modèle à partir d'un état $u(t)$ de trouver le prochain état $u(t+1)$ d'où la nécessité de faire un décalage dans notre entrée et notre sortie pour avoir des couples entrée-sortie cohérents.\n",
    "De plus une fois que notre modèle sera capable de faire : $u(t) → u(t+1)$ on pourra l'adapter pour par exemple :\n",
    "- prendre $u(t_{0})$\n",
    "- le passer dans le modèle $u(t_{1})$\n",
    "- réinjecter $u(t_{1}) → u(t_{2})$\n",
    "\n",
    "Donc on pourra propager le système dans le temps et étudier la stabilité et la cohérence dans le temps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de035438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (2921, 151) y_train: (2921, 150)\n",
      "X_val  : (729, 151) y_val  : (729, 150)\n"
     ]
    }
   ],
   "source": [
    "# one-step forecast :\n",
    "\n",
    "# suppression de la dernière ligne pour l'entrée\n",
    "X_train_state = PCsTrain[:-1, :]\n",
    "\n",
    "# suppression de la première ligne de la cible\n",
    "y_train = PCsTrain[1:, :]\n",
    "\n",
    "# ajout du temps comme feature\n",
    "t_train_used = tTrain[:-1]\n",
    "t_train_used = t_train_used.reshape(-1, 1)\n",
    "\n",
    "# assemblage de l'état avec le temps\n",
    "X_train = np.concatenate([X_train_state, t_train_used], axis=1)\n",
    "\n",
    "# même opérations sur le bloc validation\n",
    "X_val_state = PCsVal[:-1, :]\n",
    "t_val_used  = tVal[:-1].reshape(-1, 1)     \n",
    "y_val = PCsVal[1:, :]                      \n",
    "\n",
    "X_val = np.hstack([X_val_state, t_val_used])  \n",
    "\n",
    "# Vérifications (à supprimer) ##############\n",
    "\n",
    "print(\"X_train:\", X_train.shape, \"y_train:\", y_train.shape)\n",
    "print(\"X_val  :\", X_val.shape,   \"y_val  :\", y_val.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0616bf17",
   "metadata": {},
   "source": [
    "### Qu'est-ce qu'on obtient avec ce code ?\n",
    "On obtient ainsi un état réduit avec une date puisque la dynamique n'est pas forcément stationnaire : le réchauffement est global avec des tendances lentes et des changement de régimes. Ainsi avec l'ajout du temps le modèle pourra comparer la dynamique entre années sans pour autant casser notre structure $u(t) → u(t+1)$.\n",
    "\n",
    "### Pourquoi ce format est utile pour comparer les modèles ?\n",
    "Cette construction permet d'avoir l'évolution locale de notre état réduit qui pourra ensuite être utilisé pour comparer différentes familles de modèles (linéaires, non linéaires ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fa64fb",
   "metadata": {},
   "source": [
    "## Ridge\n",
    "### Pourquoi utilisons-nous le modèle de régression linéaire régularisée ?\n",
    "Dans notre situation on sait que notre cas n'est pas linéaire du type : \n",
    "\n",
    "$y = ax + b$ \n",
    "Ainsi si on utilisait un modèle de régression linéaire \"pure\" qui est très sensible au bruit on se retrouverait avec des énormes erreurs au pas suivant et on obtiendrait une divergence.\n",
    "\n",
    "Ridge est une régression linéaire avec pénalisation L2 de formule :\n",
    "$min||y- X\\beta||^{2} + \\alpha||\\beta||^2$\n",
    "Ce qui nous permet d'empêcher les coefficients de devenir trop grands et de stabiliser le problème.\n",
    "\n",
    "Enfin Ridge est particulièrement adapté aux EOF / PCA puisque les EOF sont orthogonaux dans l'espace original mais leurs coefficients temporels sont corrélés et Ridge est spécialement conçu pour gérer la multicolinéarité et les fortes dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3185a29d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleurs hyperparamètres Ridge : {'ridge__estimator__alpha': 100}\n",
      "MSE CV Ridge : 0.718700647354126\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Modèle de base\n",
    "ridge_base = MultiOutputRegressor(Ridge())\n",
    "\n",
    "# Pipeline de prétraitement et de modèle\n",
    "pipe_ridge = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"ridge\", ridge_base)\n",
    "])\n",
    "\n",
    "# Hyperparamètres\n",
    "param_grid_ridge = {\n",
    "    \"ridge__estimator__alpha\": [0.01, 0.1, 1, 10, 100]\n",
    "}\n",
    "\n",
    "# Apprentissage passé puis on valide sur le futur\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "grid_ridge = GridSearchCV(\n",
    "    pipe_ridge,\n",
    "    param_grid_ridge,\n",
    "    cv=tscv,\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_ridge.fit(X_train, y_train)\n",
    "\n",
    "ridge_best = grid_ridge.best_estimator_\n",
    "\n",
    "print(\"Meilleurs hyperparamètres Ridge :\", grid_ridge.best_params_)\n",
    "print(\"MSE CV Ridge :\", -grid_ridge.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf6a532",
   "metadata": {},
   "source": [
    "### Comment interpréter nos résultats ?\n",
    "On trouve $\\alpha = 100$ ce qui signifie que notre modèle a besoin d'une forte régulation sur les coefficients pour être optimal.\n",
    "La valeur obtenue de la MSE par validation croisée vaut environ 0.72 montre que notre dynamique d'état réduit peut être décrite en partie par une relation linéaire régularisée. L'augmentation de l'erreur pour les modes de rang élevé suggère des composantes plus bruitées et moins prédictibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69a71270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Ridge (global) : 0.9627987274205094\n",
      "RMSE par mode (Ridge) : [0.39625752 0.50029844 0.5174921  0.57668054 0.6495896  0.61422634\n",
      " 0.6522364  0.83767    0.7285807  0.8741386  0.7727087  0.8289254\n",
      " 0.76158124 0.890739   0.7651489  0.799449   0.918801   0.8040187\n",
      " 0.87714183 0.8766024  0.9098694  0.90245026 0.7986073  0.8484104\n",
      " 0.8690122  0.8084291  0.88514346 0.87056565 0.8253365  0.9660748\n",
      " 0.9101814  0.8649687  0.8528794  0.8639875  0.860115   0.92285186\n",
      " 0.92222506 0.89992183 0.8916467  0.8445249  0.95203614 0.91881645\n",
      " 0.8929505  0.8362511  0.9514442  0.90347713 0.8628406  0.93183804\n",
      " 1.0693872  1.0789129  0.9848905  0.9508435  1.1171497  0.9327653\n",
      " 0.97638875 0.98767585 0.8973125  0.91412103 0.8988933  0.9420458\n",
      " 1.0054715  0.9544596  0.9834846  0.9516665  0.91317177 0.8798058\n",
      " 0.96992844 1.093074   1.0505735  1.0270013  1.0243638  0.9065121\n",
      " 1.0274105  0.9401182  0.9857165  0.9874809  0.99427944 1.016098\n",
      " 0.9030879  1.089341   0.9383964  0.9743601  0.8944418  1.0462297\n",
      " 0.9789583  1.0560149  0.9637269  1.0382127  1.0325665  1.0263377\n",
      " 1.0240148  1.0392622  0.97080743 1.0345879  1.0996407  1.0176913\n",
      " 1.0067534  0.97509575 0.98553556 1.0767443  1.0357702  0.9922429\n",
      " 0.9950973  1.0433786  0.99162334 1.0362297  1.0016532  1.0209075\n",
      " 1.0730358  1.0540916  0.9763719  1.0398189  1.0454425  1.0598695\n",
      " 0.9995781  1.0034804  1.0102757  0.9817085  1.097613   1.0723907\n",
      " 1.0099387  1.0747395  1.0478361  1.051152   1.1229619  1.052862\n",
      " 1.0693991  1.0379564  1.061831   1.0590246  1.0231972  1.0615015\n",
      " 1.0976683  0.99946624 0.99552375 1.078061   1.1151471  1.0959184\n",
      " 1.0099922  1.0225186  1.0112748  1.0259727  1.0264086  1.0898716\n",
      " 1.1239433  1.0414577  1.0203726  1.0751455  1.0789295  1.0589082 ]\n"
     ]
    }
   ],
   "source": [
    "y_pred_ridge = ridge_best.predict(X_val)\n",
    "\n",
    "mse_ridge = mean_squared_error(y_val, y_pred_ridge)\n",
    "rmse_ridge = np.sqrt(mse_ridge)\n",
    "\n",
    "print(\"RMSE Ridge (global) :\", rmse_ridge)\n",
    "\n",
    "rmse_per_mode_ridge = np.sqrt(np.mean((y_val - y_pred_ridge)**2, axis=0))\n",
    "print(\"RMSE par mode (Ridge) :\", rmse_per_mode_ridge)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0daca9a",
   "metadata": {},
   "source": [
    "### Comment interpréter nos résultats ?\n",
    "Le modèle de régression linéaire régularisée (Ridge) obtient une RMSE globale de 0.96 sur le jeu de validation, ce qui constitue la meilleure performance parmi l’ensemble des modèles testés.\n",
    "\n",
    "L’analyse de la RMSE par mode EOF montre une augmentation progressive de l’erreur avec le rang du mode. Les premiers modes, qui concentrent la majorité de la variance du champ de SST, sont prédits avec une erreur relativement faible, tandis que les modes de rang élevé présentent une erreur plus importante. Ce comportement est cohérent avec la décroissance de l’énergie associée aux modes EOF et avec le caractère plus bruité des composantes de haut rang.\n",
    "\n",
    "La valeur optimale élevée du paramètre de régularisation (α = 100) indique que la stabilité du modèle repose sur une forte contrainte des coefficients, ce qui confirme que la dynamique prédictible est dominée par des structures larges et robustes, plutôt que par des interactions fines entre modes.\n",
    "\n",
    "Ces résultats suggèrent que la dynamique de l’état réduit est majoritairement linéaire et que la régression Ridge constitue une baseline robuste et efficace pour la prédiction à court terme.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153ff88c",
   "metadata": {},
   "source": [
    "## Modèle MLP (Multi-Layer Perceptron)\n",
    "### Pourquoi choisir ce modèle ?\n",
    "\n",
    "Après avoir établi une référence à l’aide d’un modèle linéaire régularisé (Ridge), nous introduisons un réseau de neurones de type MLP afin d’évaluer l’apport de la non-linéarité dans la modélisation de la dynamique de l’état réduit.\n",
    "\n",
    "Le MLP permet d’approximer des relations non linéaires entre l’état réduit au temps t et l’état au temps t+Δt, sans introduire de mémoire temporelle explicite. Il constitue ainsi une extension naturelle du modèle linéaire, tout en conservant une formulation instantanée du type one-step forecast.\n",
    "\n",
    "L’objectif de ce modèle est de déterminer si la relation d’évolution de l’état réduit présente des non-linéarités suffisamment marquées pour justifier l’utilisation d’un modèle plus expressif qu’une simple régression linéaire.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50ffd11c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleurs hyperparamètres MLP : {'mlp__activation': 'relu', 'mlp__alpha': 0.001, 'mlp__hidden_layer_sizes': (64,), 'mlp__learning_rate_init': 0.001}\n",
      "MSE CV MLP : 1.0430416345596314\n",
      "RMSE MLP (global) : 1.1555462835064203\n",
      "RMSE par mode (MLP) : [0.6356537  0.70324665 0.72292954 0.7647652  0.9030558  0.8601517\n",
      " 0.8901438  1.0802373  0.955038   1.0804075  0.9537617  1.0445734\n",
      " 0.96162486 1.1340711  0.90238893 1.035353   1.1144886  0.9989324\n",
      " 1.1075387  1.0937221  1.0552409  1.2001823  0.96730167 1.1110024\n",
      " 1.0848904  0.98859185 1.0632296  1.0677372  1.0299269  1.102887\n",
      " 1.1733805  1.0488017  1.1188991  1.058531   1.0742584  1.1349846\n",
      " 1.0860056  1.0882188  1.0416571  1.0586542  1.1216917  1.154137\n",
      " 1.1152745  1.0036047  1.1648841  1.0839219  1.0800401  1.1205515\n",
      " 1.3302065  1.3142676  1.2039918  1.190649   1.4034269  1.1554232\n",
      " 1.1938664  1.117619   1.0942965  1.1548995  1.1112602  1.1177256\n",
      " 1.2105688  1.163504   1.2321111  1.1730967  1.0670959  1.0909406\n",
      " 1.1702598  1.3746955  1.2705066  1.2833209  1.1673167  1.0581028\n",
      " 1.1600431  1.1304237  1.1471102  1.159986   1.2379441  1.1748817\n",
      " 1.1340188  1.2805638  1.1346176  1.1540611  1.0334015  1.1846052\n",
      " 1.1785877  1.2687212  1.1269226  1.2175001  1.2708644  1.170895\n",
      " 1.223941   1.3212302  1.1703261  1.2108833  1.2120447  1.1987512\n",
      " 1.2247442  1.1792169  1.196636   1.2684287  1.2508852  1.1529162\n",
      " 1.174094   1.2003174  1.204615   1.239611   1.1655555  1.2367033\n",
      " 1.2939062  1.2045602  1.1865703  1.2841375  1.2282308  1.2466351\n",
      " 1.2092003  1.1592556  1.1609871  1.1495597  1.2566656  1.3050272\n",
      " 1.1994772  1.2431616  1.2355882  1.2554364  1.3200104  1.2118149\n",
      " 1.231036   1.2142773  1.1975374  1.2798985  1.2364442  1.2294061\n",
      " 1.2521245  1.1454391  1.1531123  1.2553335  1.2547911  1.3030671\n",
      " 1.1742449  1.2200507  1.1964769  1.1837136  1.1807673  1.2300426\n",
      " 1.2645226  1.2187492  1.1818001  1.1744915  1.2347245  1.2396566 ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# Validation croisée adaptée aux séries temporelles\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "mlp_base = MLPRegressor(\n",
    "    max_iter=500,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Pipeline\n",
    "pipe_mlp = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"mlp\", mlp_base)\n",
    "])\n",
    "\n",
    "param_grid_mlp = {\n",
    "    \"mlp__hidden_layer_sizes\": [(64,), (128,), (64, 64)],\n",
    "    \"mlp__activation\": [\"relu\"],\n",
    "    \"mlp__alpha\": [1e-4, 1e-3],\n",
    "    \"mlp__learning_rate_init\": [1e-3]\n",
    "}\n",
    "\n",
    "grid_mlp = GridSearchCV(\n",
    "    pipe_mlp,\n",
    "    param_grid_mlp,\n",
    "    cv=tscv,\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_mlp.fit(X_train, y_train)\n",
    "\n",
    "mlp_best = grid_mlp.best_estimator_\n",
    "\n",
    "print(\"Meilleurs hyperparamètres MLP :\", grid_mlp.best_params_)\n",
    "print(\"MSE CV MLP :\", -grid_mlp.best_score_)\n",
    "\n",
    "y_pred_mlp = mlp_best.predict(X_val)\n",
    "\n",
    "mse_mlp = mean_squared_error(y_val, y_pred_mlp)\n",
    "rmse_mlp = np.sqrt(mse_mlp)\n",
    "\n",
    "print(\"RMSE MLP (global) :\", rmse_mlp)\n",
    "\n",
    "# RMSE par mode (analyse fine comme pour Ridge)\n",
    "rmse_per_mode_mlp = np.sqrt(np.mean((y_val - y_pred_mlp)**2, axis=0))\n",
    "print(\"RMSE par mode (MLP) :\", rmse_per_mode_mlp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15e0aab",
   "metadata": {},
   "source": [
    "### Comment interpréter nos résultats ?\n",
    "Le modèle MLP, configuré avec une seule couche cachée de 64 neurones et une régularisation modérée, obtient une RMSE globale de 1.16, nettement supérieure à celle du modèle Ridge.\n",
    "\n",
    "L’analyse des erreurs par mode montre que le MLP présente une dégradation systématique des performances sur l’ensemble des modes EOF, y compris les modes dominants. L’introduction de non-linéarités ne permet donc pas d’améliorer la prédiction de l’état réduit, et conduit au contraire à une augmentation de l’erreur globale.\n",
    "\n",
    "Ce résultat suggère que les relations non linéaires instantanées entre l’état réduit au temps t et l’état au temps t+Δt sont soit faibles, soit masquées par le bruit, et que la complexité supplémentaire du MLP n’est pas justifiée dans ce cadre."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0be0e1a",
   "metadata": {},
   "source": [
    "## Modèle LSTM - Réseau récurrent à mémoire longue\n",
    "### Pourquoi utiliser le modèle LSTM ?\n",
    "\n",
    "Les modèles précédents reposent sur une hypothèse de type markovienne, dans laquelle l’évolution de l’état réduit dépend uniquement de l’état courant. Or, les systèmes océaniques sont connus pour présenter des dynamiques lentes et intégratives, impliquant une mémoire temporelle sur plusieurs pas de temps.\n",
    "\n",
    "Le modèle LSTM est conçu pour capturer ce type de dépendances temporelles en prenant en entrée une séquence d’états passés. Il permet ainsi de tester l’hypothèse selon laquelle l’évolution de l’état réduit dépend non seulement de l’état instantané, mais également de son historique récent.\n",
    "\n",
    "L’objectif de ce modèle est donc d’évaluer l’apport d’une mémoire temporelle explicite dans la prédiction de la dynamique réduite de la SST.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c22d9823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_seq_train: (2912, 10, 150)\n",
      "y_seq_train: (2912, 150)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def make_sequences(PCs, window):\n",
    "    X_seq = []\n",
    "    y_seq = []\n",
    "    for i in range(len(PCs) - window):\n",
    "        X_seq.append(PCs[i:i+window, :])      # (window, 150)\n",
    "        y_seq.append(PCs[i+window, :])        # (150,)\n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "window = 10  # longueur de séquence\n",
    "\n",
    "X_seq_train, y_seq_train = make_sequences(PCsTrain, window)\n",
    "X_seq_val,   y_seq_val   = make_sequences(PCsVal, window)\n",
    "\n",
    "print(\"X_seq_train:\", X_seq_train.shape)  # (n_samples, window, 150)\n",
    "print(\"y_seq_train:\", y_seq_train.shape)  # (n_samples, 150)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e21168d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "\n",
    "n_timesteps = X_seq_train.shape[1]   # longueur de la fenêtre temporelle\n",
    "n_features  = X_seq_train.shape[2]   # nombre de modes EOF\n",
    "\n",
    "lstm_model = keras.Sequential([\n",
    "    keras.Input(shape=(n_timesteps, n_features)),\n",
    "    layers.LSTM(64),\n",
    "    layers.Dense(n_features)\n",
    "])\n",
    "\n",
    "lstm_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss=\"mse\"\n",
    ")\n",
    "\n",
    "lstm_reg = KerasRegressor(\n",
    "    model=lstm_model,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    verbose=0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a8ae6c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleurs hyperparamètres LSTM : {'batch_size': 32, 'epochs': 50, 'learning_rate': 0.0005, 'n_units': 32}\n",
      "RMSE LSTM (global) : 1.201587933691575\n"
     ]
    }
   ],
   "source": [
    "param_grid_lstm = {\n",
    "    \"n_units\": [32, 64],\n",
    "    \"learning_rate\": [1e-3, 5e-4],\n",
    "    \"batch_size\": [32],\n",
    "    \"epochs\": [50],\n",
    "}\n",
    "\n",
    "grid_lstm = GridSearchCV(\n",
    "    lstm_reg,\n",
    "    param_grid_lstm,\n",
    "    cv=3,\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_lstm.fit(X_seq_train, y_seq_train)\n",
    "\n",
    "print(\"Meilleurs hyperparamètres LSTM :\", grid_lstm.best_params_)\n",
    "\n",
    "lstm_best = grid_lstm.best_estimator_\n",
    "\n",
    "y_pred_lstm = lstm_best.predict(X_seq_val)\n",
    "mse_lstm = mean_squared_error(y_seq_val, y_pred_lstm)\n",
    "rmse_lstm = np.sqrt(mse_lstm)\n",
    "print(\"RMSE LSTM (global) :\", rmse_lstm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b18b89d",
   "metadata": {},
   "source": [
    "### Comment interpréter nos résultats ?\n",
    "Le modèle LSTM, conçu pour exploiter une mémoire temporelle explicite, obtient une RMSE globale de 1.20, ce qui correspond à la performance la plus faible parmi les modèles testés.\n",
    "\n",
    "Malgré l’introduction d’une fenêtre temporelle de longueur 10, le LSTM ne parvient pas à améliorer la prédiction de l’état réduit par rapport aux modèles non récurrents. Cela indique que l’information contenue dans les états passés supplémentaires n’apporte pas de gain significatif pour la prédiction à un pas de temps dans ce cadre.\n",
    "\n",
    "Ce résultat suggère que la dynamique de l’état réduit est essentiellement locale dans le temps et qu’une hypothèse markovienne de premier ordre constitue une approximation suffisante."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542c79fb",
   "metadata": {},
   "source": [
    "## Modèle GRU - Réseau récurrent simplifié\n",
    "### Pourquoi utiliser le modèle GRU ?\n",
    "\n",
    "Le modèle GRU constitue une alternative au LSTM, reposant sur une architecture plus simple et un nombre réduit de paramètres. Il est souvent utilisé lorsque les données disponibles sont limitées ou lorsque l’on souhaite réduire le risque de sur-apprentissage.\n",
    "\n",
    "Dans ce travail, le GRU est utilisé afin de comparer deux architectures récurrentes et de déterminer si une modélisation temporelle plus légère permet de mieux capturer la dynamique de l’état réduit que le LSTM.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82f75a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleurs hyperparamètres GRU : {'batch_size': 32, 'epochs': 50, 'learning_rate': 0.0005, 'n_units': 64}\n",
      "RMSE GRU (global) : 1.1746598786285307\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import GRU\n",
    "\n",
    "# Dimensions des séquences\n",
    "n_timesteps = X_seq_train.shape[1]  \n",
    "n_features  = X_seq_train.shape[2]  \n",
    "\n",
    "# Définition du modèle GRU (inline)\n",
    "gru_model = keras.Sequential([\n",
    "    keras.Input(shape=(n_timesteps, n_features)),\n",
    "    GRU(64),\n",
    "    layers.Dense(n_features)\n",
    "])\n",
    "\n",
    "gru_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss=\"mse\"\n",
    ")\n",
    "\n",
    "# Wrapper SciKeras pour intégration avec scikit-learn\n",
    "gru_reg = KerasRegressor(\n",
    "    model=gru_model,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "param_grid_gru = {\n",
    "    \"model__gru__units\": [32, 64],        # nombre de neurones GRU\n",
    "    \"optimizer__learning_rate\": [1e-3, 5e-4],\n",
    "    \"batch_size\": [32],\n",
    "    \"epochs\": [50]\n",
    "}\n",
    "\n",
    "grid_gru = GridSearchCV(\n",
    "    gru_reg,\n",
    "    param_grid_gru,\n",
    "    cv=3,\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_gru.fit(X_seq_train, y_seq_train)\n",
    "\n",
    "print(\"Meilleurs hyperparamètres GRU :\", grid_gru.best_params_)\n",
    "\n",
    "gru_best = grid_gru.best_estimator_\n",
    "\n",
    "# Prédiction sur la validation\n",
    "y_pred_gru = gru_best.predict(X_seq_val)\n",
    "\n",
    "# Calcul des erreurs\n",
    "mse_gru = mean_squared_error(y_seq_val, y_pred_gru)\n",
    "rmse_gru = np.sqrt(mse_gru)\n",
    "\n",
    "print(\"RMSE GRU (global) :\", rmse_gru)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01494d9d",
   "metadata": {},
   "source": [
    "### Comment interpréter nos résultats ?\n",
    "Le modèle GRU obtient une RMSE globale de 1.17, légèrement inférieure à celle du LSTM mais toujours supérieure à celles des modèles non récurrents.\n",
    "\n",
    "La meilleure performance relative du GRU par rapport au LSTM peut s’expliquer par une architecture plus simple et un nombre réduit de paramètres, mieux adaptée à la taille limitée du jeu de données. Néanmoins, l’introduction d’une mémoire temporelle explicite ne permet pas d’atteindre les performances du modèle linéaire régularisé.\n",
    "\n",
    "Ces résultats confirment que, dans ce cas d’étude, la mémoire temporelle sur plusieurs pas n’est pas un facteur déterminant pour la prédiction à court terme de l’état réduit.\n",
    "\n",
    "---\n",
    "## Conclusion \n",
    "L’ensemble des modèles de Machine Learning testés met en évidence une hiérarchie claire des performances. La régression linéaire régularisée (Ridge) obtient la meilleure performance globale, suivie du MLP, puis des modèles récurrents GRU et LSTM.\n",
    "\n",
    "Le fait que le modèle linéaire régularisé surpasse des architectures plus complexes suggère que la dynamique projetée sur l’état réduit de la SST est majoritairement linéaire et faiblement dépendante de l’historique temporel à court terme. Les non-linéarités instantanées et la mémoire temporelle explicite n’apportent pas de gain significatif dans la prédiction one-step.\n",
    "\n",
    "Dans ce contexte, le modèle Ridge apparaît comme le meilleur compromis entre performance, stabilité numérique et interprétabilité. Il constitue donc le modèle retenu pour la suite de l’étude, et sert de référence pour discuter des limites du ML classique et de l’intérêt potentiel d’approches plus structurées.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (m1Project_SciML)",
   "language": "python",
   "name": "m1project_sciml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
