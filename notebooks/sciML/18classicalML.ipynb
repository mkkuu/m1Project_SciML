{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "612bde4e",
   "metadata": {},
   "source": [
    "# Classic Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1ef9de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2922, 150) (730, 150)\n",
      "(2922,) (730,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "data = np.load(\"../../data/processed/sstReducedStateCOPERNICUS20102019Prepared.npz\")\n",
    "\n",
    "PCsTrain = data[\"PCsTrain\"]\n",
    "PCsVal = data[\"PCsVal\"]\n",
    "tTrain = data[\"tTrain\"]\n",
    "tVal = data[\"tVal\"]\n",
    "std = data[\"std\"]\n",
    "\n",
    "# Vérifications (à supprimer) ############\n",
    "\n",
    "print(PCsTrain.shape, PCsVal.shape)\n",
    "print(tTrain.shape, tVal.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de035438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (2921, 151) y_train: (2921, 150)\n",
      "X_val  : (729, 151) y_val  : (729, 150)\n"
     ]
    }
   ],
   "source": [
    "# one-step forecast :\n",
    "\n",
    "#suppression de la dernière ligne pour l'entrée\n",
    "X_train_state = PCsTrain[:-1, :]\n",
    "\n",
    "#suppression de la première ligne de la cible\n",
    "y_train = PCsTrain[1:, :]\n",
    "\n",
    "t_train_used = tTrain[:-1]\n",
    "t_train_used = t_train_used.reshape(-1, 1)\n",
    "\n",
    "X_train = np.concatenate([X_train_state, t_train_used], axis=1)\n",
    "\n",
    "# Vérifications (à supprimer) ##############\n",
    "\n",
    "X_val_state = PCsVal[:-1, :]\n",
    "t_val_used  = tVal[:-1].reshape(-1, 1)     # (729, 1)\n",
    "y_val = PCsVal[1:, :]                      # (729, 150)\n",
    "\n",
    "X_val = np.hstack([X_val_state, t_val_used])  # (729, 151)\n",
    "\n",
    "print(\"X_train:\", X_train.shape, \"y_train:\", y_train.shape)\n",
    "print(\"X_val  :\", X_val.shape,   \"y_val  :\", y_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3185a29d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleurs hyperparamètres Ridge : {'ridge__estimator__alpha': 100}\n",
      "MSE CV Ridge : 0.718700647354126\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Base model\n",
    "ridge_base = MultiOutputRegressor(Ridge())\n",
    "\n",
    "pipe_ridge = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"ridge\", ridge_base)\n",
    "])\n",
    "\n",
    "param_grid_ridge = {\n",
    "    \"ridge__estimator__alpha\": [0.01, 0.1, 1, 10, 100]\n",
    "}\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "grid_ridge = GridSearchCV(\n",
    "    pipe_ridge,\n",
    "    param_grid_ridge,\n",
    "    cv=tscv,\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_ridge.fit(X_train, y_train)\n",
    "\n",
    "ridge_best = grid_ridge.best_estimator_\n",
    "\n",
    "print(\"Meilleurs hyperparamètres Ridge :\", grid_ridge.best_params_)\n",
    "print(\"MSE CV Ridge :\", -grid_ridge.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69a71270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Ridge (global) : 0.9627987274205094\n",
      "RMSE par mode (Ridge) : [0.39625752 0.50029844 0.5174921  0.57668054 0.6495896  0.61422634\n",
      " 0.6522364  0.83767    0.7285807  0.8741386  0.7727087  0.8289254\n",
      " 0.76158124 0.890739   0.7651489  0.799449   0.918801   0.8040187\n",
      " 0.87714183 0.8766024  0.9098694  0.90245026 0.7986073  0.8484104\n",
      " 0.8690122  0.8084291  0.88514346 0.87056565 0.8253365  0.9660748\n",
      " 0.9101814  0.8649687  0.8528794  0.8639875  0.860115   0.92285186\n",
      " 0.92222506 0.89992183 0.8916467  0.8445249  0.95203614 0.91881645\n",
      " 0.8929505  0.8362511  0.9514442  0.90347713 0.8628406  0.93183804\n",
      " 1.0693872  1.0789129  0.9848905  0.9508435  1.1171497  0.9327653\n",
      " 0.97638875 0.98767585 0.8973125  0.91412103 0.8988933  0.9420458\n",
      " 1.0054715  0.9544596  0.9834846  0.9516665  0.91317177 0.8798058\n",
      " 0.96992844 1.093074   1.0505735  1.0270013  1.0243638  0.9065121\n",
      " 1.0274105  0.9401182  0.9857165  0.9874809  0.99427944 1.016098\n",
      " 0.9030879  1.089341   0.9383964  0.9743601  0.8944418  1.0462297\n",
      " 0.9789583  1.0560149  0.9637269  1.0382127  1.0325665  1.0263377\n",
      " 1.0240148  1.0392622  0.97080743 1.0345879  1.0996407  1.0176913\n",
      " 1.0067534  0.97509575 0.98553556 1.0767443  1.0357702  0.9922429\n",
      " 0.9950973  1.0433786  0.99162334 1.0362297  1.0016532  1.0209075\n",
      " 1.0730358  1.0540916  0.9763719  1.0398189  1.0454425  1.0598695\n",
      " 0.9995781  1.0034804  1.0102757  0.9817085  1.097613   1.0723907\n",
      " 1.0099387  1.0747395  1.0478361  1.051152   1.1229619  1.052862\n",
      " 1.0693991  1.0379564  1.061831   1.0590246  1.0231972  1.0615015\n",
      " 1.0976683  0.99946624 0.99552375 1.078061   1.1151471  1.0959184\n",
      " 1.0099922  1.0225186  1.0112748  1.0259727  1.0264086  1.0898716\n",
      " 1.1239433  1.0414577  1.0203726  1.0751455  1.0789295  1.0589082 ]\n"
     ]
    }
   ],
   "source": [
    "y_pred_ridge = ridge_best.predict(X_val)\n",
    "\n",
    "mse_ridge = mean_squared_error(y_val, y_pred_ridge)\n",
    "rmse_ridge = np.sqrt(mse_ridge)\n",
    "\n",
    "print(\"RMSE Ridge (global) :\", rmse_ridge)\n",
    "\n",
    "rmse_per_mode_ridge = np.sqrt(np.mean((y_val - y_pred_ridge)**2, axis=0))\n",
    "print(\"RMSE par mode (Ridge) :\", rmse_per_mode_ridge)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c22d9823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_seq_train: (2912, 10, 150)\n",
      "y_seq_train: (2912, 150)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def make_sequences(PCs, window):\n",
    "    X_seq = []\n",
    "    y_seq = []\n",
    "    for i in range(len(PCs) - window):\n",
    "        X_seq.append(PCs[i:i+window, :])      # (window, 150)\n",
    "        y_seq.append(PCs[i+window, :])        # (150,)\n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "window = 10  # longueur de séquence\n",
    "\n",
    "X_seq_train, y_seq_train = make_sequences(PCsTrain, window)\n",
    "X_seq_val,   y_seq_val   = make_sequences(PCsVal, window)\n",
    "\n",
    "print(\"X_seq_train:\", X_seq_train.shape)  # (n_samples, window, 150)\n",
    "print(\"y_seq_train:\", y_seq_train.shape)  # (n_samples, 150)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e21168d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "n_timesteps = X_seq_train.shape[1]   # = window\n",
    "n_features  = X_seq_train.shape[2]   # = 150\n",
    "\n",
    "def build_lstm_model(n_units=64, learning_rate=1e-3):\n",
    "    inputs = keras.Input(shape=(n_timesteps, n_features))\n",
    "    x = layers.LSTM(n_units)(inputs)\n",
    "    outputs = layers.Dense(n_features)(x)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss=\"mse\"\n",
    "    )\n",
    "    return model\n",
    "\n",
    "lstm_reg = KerasRegressor(\n",
    "    model=build_lstm_model,\n",
    "    n_units=64,\n",
    "    learning_rate=1e-3,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    verbose=0,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a8ae6c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleurs hyperparamètres LSTM : {'batch_size': 32, 'epochs': 50, 'learning_rate': 0.0005, 'n_units': 32}\n",
      "RMSE LSTM (global) : 1.2018203597559927\n"
     ]
    }
   ],
   "source": [
    "param_grid_lstm = {\n",
    "    \"n_units\": [32, 64],\n",
    "    \"learning_rate\": [1e-3, 5e-4],\n",
    "    \"batch_size\": [32],\n",
    "    \"epochs\": [50],\n",
    "}\n",
    "\n",
    "grid_lstm = GridSearchCV(\n",
    "    lstm_reg,\n",
    "    param_grid_lstm,\n",
    "    cv=3,\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_lstm.fit(X_seq_train, y_seq_train)\n",
    "\n",
    "print(\"Meilleurs hyperparamètres LSTM :\", grid_lstm.best_params_)\n",
    "\n",
    "lstm_best = grid_lstm.best_estimator_\n",
    "\n",
    "y_pred_lstm = lstm_best.predict(X_seq_val)\n",
    "mse_lstm = mean_squared_error(y_seq_val, y_pred_lstm)\n",
    "rmse_lstm = np.sqrt(mse_lstm)\n",
    "print(\"RMSE LSTM (global) :\", rmse_lstm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b82f75a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleurs hyperparamètres GRU : {'batch_size': 32, 'epochs': 50, 'learning_rate': 0.0005, 'n_units': 64}\n",
      "RMSE GRU (global) : 1.1731378490169093\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import GRU\n",
    "\n",
    "def build_gru_model(n_units=64, learning_rate=1e-3):\n",
    "    inputs = keras.Input(shape=(n_timesteps, n_features))\n",
    "    x = GRU(n_units)(inputs)\n",
    "    outputs = layers.Dense(n_features)(x)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss=\"mse\"\n",
    "    )\n",
    "    return model\n",
    "\n",
    "gru_reg = KerasRegressor(\n",
    "    model=build_gru_model,\n",
    "    n_units=64,\n",
    "    learning_rate=1e-3,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    verbose=0,\n",
    ")\n",
    "\n",
    "param_grid_gru = {\n",
    "    \"n_units\": [32, 64],\n",
    "    \"learning_rate\": [1e-3, 5e-4],\n",
    "    \"batch_size\": [32],\n",
    "    \"epochs\": [50],\n",
    "}\n",
    "\n",
    "grid_gru = GridSearchCV(\n",
    "    gru_reg,\n",
    "    param_grid_gru,\n",
    "    cv=3,\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_gru.fit(X_seq_train, y_seq_train)\n",
    "\n",
    "print(\"Meilleurs hyperparamètres GRU :\", grid_gru.best_params_)\n",
    "\n",
    "gru_best = grid_gru.best_estimator_\n",
    "\n",
    "y_pred_gru = gru_best.predict(X_seq_val)\n",
    "mse_gru = mean_squared_error(y_seq_val, y_pred_gru)\n",
    "rmse_gru = np.sqrt(mse_gru)\n",
    "print(\"RMSE GRU (global) :\", rmse_gru)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (m1Project_SciML)",
   "language": "python",
   "name": "m1project_sciml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
